{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ROOT_DIR'] = os.getcwd()\n",
    "os.environ['DATA_INFO_DIR'] = '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info'\n",
    "os.environ['DATA_DIR'] = '/Users/cho-seonggeun/Documents/GitHub/SAMIL/TMED2/approved_users_only/view_and_diagnosis_labeled_set'\n",
    "os.environ['CHECKPOINT_DIR'] = '/Users/cho-seonggeun/Documents/GitHub/SAMIL/model_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    os.chdir('runs/SAMIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash launch_experiment.sh run_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/25/2024 21:41:53 - INFO - __main__ -   {'dataset_name': 'echo', 'data_seed': 0, 'development_size': 'DEV479', 'training_seed': 0, 'sampling_strategy': 'first_frame', 'train_epoch': 2000, 'start_epoch': 0, 'eval_every_Xepoch': 1, 'Pretrained': 'Whole', 'resume': 'last_checkpoint.pth.tar', 'resume_checkpoint_fullpath': '', 'train_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/experiments/SAMIL/Pretrained-Whole/data_seed0/training_seed0/DEV479/', 'data_info_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info', 'data_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/TMED2/approved_users_only/view_and_diagnosis_labeled_set', 'checkpoint_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/model_checkpoints', 'train_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/train_studies.csv', 'val_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/val_studies.csv', 'test_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/test_studies.csv', 'lr': 5e-05, 'lr_warmup_epochs': 0, 'lr_schedule_type': 'CosineLR', 'lr_cycle_epochs': 2000, 'wd': 0.0001, 'optimizer_type': 'SGD', 'nesterov': True, 'ema_decay': 0.999, 'num_classes': 3, 'batch_size': 1, 'num_workers': 8, 'patience': 200, 'early_stopping_warmup': 200, 'T': 0.03, 'lambda_ViewRegularization': 5.0, 'view_checkpoint_path': '', 'ViewRegularization_warmup_pos': 0.4, 'ViewRegularization_warmup_schedule_type': 'Linear', 'use_class_weights': 'True', 'class_weights': '0.25,0.25,0.25', 'augmentation': 'RandAug', 'use_data_normalization': 'False', 'device': 'cpu'}\n",
      "setting training seed0\n",
      "!!!!!!!!Using pre-calculated class weights!!!!!!!!\n",
      "args.resume_checkpoint_fullpath: /Users/cho-seonggeun/Documents/GitHub/SAMIL/experiments/SAMIL/Pretrained-Whole/data_seed0/training_seed0/DEV479/ViewRegularization_warmup-Linear_Optimizer-SGD_LrSchedule-CosineLR_LrCycleEpochs-2000_lr-5e-05_wd-0.0001_T-0.03_lambdaViewRegularization-5.0/last_checkpoint.pth.tar\n",
      "Created dataset\n",
      "train: 360, trainmemory: 360, val: 119, test: 120\n",
      "04/25/2024 21:42:43 - INFO - src.SAMIL.libml.models.view_classifier -   Model: WideResNet 28x2\n",
      "04/25/2024 21:42:43 - INFO - __main__ -   Total params for View Model: 5.93M\n",
      "!!!!!!!!!!!!!!!!!!!!!initializing from pretrained checkpoint!!!!!!!!!!!!!!!!!!!!!\n",
      "04/25/2024 21:42:43 - INFO - __main__ -   Total params: 2.31M\n",
      "self.param_keys: ['feature_extractor_part1.0.weight', 'feature_extractor_part1.0.bias', 'feature_extractor_part1.3.weight', 'feature_extractor_part1.3.bias', 'feature_extractor_part1.6.weight', 'feature_extractor_part1.6.bias', 'feature_extractor_part1.9.weight', 'feature_extractor_part1.9.bias', 'feature_extractor_part2.0.weight', 'feature_extractor_part2.0.bias', 'feature_extractor_part3.0.weight', 'feature_extractor_part3.0.bias', 'feature_extractor_part3.2.weight', 'feature_extractor_part3.2.bias', 'attention_V.0.weight', 'attention_V.0.bias', 'attention_V.2.weight', 'attention_V.2.bias', 'attention_U.0.weight', 'attention_U.0.bias', 'attention_U.2.weight', 'attention_U.2.bias', 'classifier.0.weight', 'classifier.0.bias']\n",
      "self.buffer_keys: []\n",
      "!!!!Does not have checkpoint yet!!!!\n",
      "04/25/2024 21:42:43 - INFO - __main__ -   ***** Running training *****\n",
      "04/25/2024 21:42:43 - INFO - __main__ -     Task = echo\n",
      "04/25/2024 21:42:43 - INFO - __main__ -     Num Epochs = 2000\n",
      "04/25/2024 21:42:43 - INFO - __main__ -     Total optimization steps = 720000\n",
      "  0%|                                                  | 0/2000 [00:00<?, ?it/s]\n",
      "  0%|                                                   | 0/360 [00:00<?, ?it/s]\u001b[AInside forward: input x shape: torch.Size([1, 20, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([20, 3, 112, 112])\n",
      "/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/libml/utils/misc.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predicted_relative_relevance = F.softmax(predicted_relevance/args.T)\n",
      "Inside forward: input x shape: torch.Size([1, 92, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([92, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 61, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([61, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 70, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([70, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 68, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([68, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 75, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([75, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 55, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([55, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 91, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([91, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 67, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([67, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 65, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([65, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 64, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([64, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 70, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([70, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 86, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([86, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 92, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([92, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 58, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([58, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 81, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([81, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 95, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([95, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 96, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([96, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 55, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([55, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 70, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([70, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 64, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([64, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 65, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([65, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 78, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([78, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 65, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([65, 3, 112, 112])\n",
      "Inside forward: input x shape: torch.Size([1, 72, 3, 112, 112])\n",
      "Inside forward: after squeeze x shape: torch.Size([72, 3, 112, 112])\n",
      "^C\n",
      "  0%|                                                  | 0/2000 [01:33<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/main.py\", line 826, in <module>\n",
      "    main(args, brief_summary)\n",
      "  File \"/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/main.py\", line 504, in main\n",
      "    TotalLoss_list, LabeledCEloss_list, ViewRegularizationLoss_list, scaled_ViewRegularizationLoss_list = train_one_epoch(args, weights, train_loader, model, ema_model, view_model, optimizer, scheduler, epoch)\n",
      "                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/libml/utils/misc.py\", line 91, in train_one_epoch\n",
      "    outputs, attentions = model(data)\n",
      "                          ^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/libml/models/model.py\", line 73, in forward\n",
      "    H = self.feature_extractor_part1(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n",
      "    return F.max_pool2d(input, self.kernel_size, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_jit_internal.py\", line 488, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash launch_experiment.sh run_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/25/2024 19:42:25 - INFO - __main__ -   {'dataset_name': 'echo', 'data_seed': 0, 'development_size': 'DEV479', 'training_seed': 0, 'sampling_strategy': 'first_frame', 'train_epoch': 2000, 'start_epoch': 0, 'eval_every_Xepoch': 1, 'Pretrained': 'NoPretrain', 'resume': 'last_checkpoint.pth.tar', 'resume_checkpoint_fullpath': '', 'train_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/experiments/SAMIL/Pretrained-NoPretrain/data_seed0/training_seed0/DEV479/', 'data_info_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info', 'data_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/TMED2/approved_users_only/view_and_diagnosis_labeled_set', 'checkpoint_dir': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/model_checkpoints', 'train_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/train_studies.csv', 'val_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/val_studies.csv', 'test_PatientStudy_list_path': '/Users/cho-seonggeun/Documents/GitHub/SAMIL/data_info/DataPartition/seed0/DEV479/FullyLabeledSet_studies/test_studies.csv', 'lr': 5e-05, 'lr_warmup_epochs': 0, 'lr_schedule_type': 'CosineLR', 'lr_cycle_epochs': 2000, 'wd': 0.0001, 'optimizer_type': 'SGD', 'nesterov': True, 'ema_decay': 0.999, 'num_classes': 3, 'batch_size': 1, 'num_workers': 8, 'patience': 200, 'early_stopping_warmup': 200, 'T': 0.03, 'lambda_ViewRegularization': 5.0, 'view_checkpoint_path': '', 'ViewRegularization_warmup_pos': 0.4, 'ViewRegularization_warmup_schedule_type': 'Linear', 'use_class_weights': 'True', 'class_weights': '0.25,0.25,0.25', 'augmentation': 'RandAug', 'use_data_normalization': 'False', 'device': 'cpu'}\n",
      "setting training seed0\n",
      "!!!!!!!!Using pre-calculated class weights!!!!!!!!\n",
      "args.resume_checkpoint_fullpath: /Users/cho-seonggeun/Documents/GitHub/SAMIL/experiments/SAMIL/Pretrained-NoPretrain/data_seed0/training_seed0/DEV479/ViewRegularization_warmup-Linear_Optimizer-SGD_LrSchedule-CosineLR_LrCycleEpochs-2000_lr-5e-05_wd-0.0001_T-0.03_lambdaViewRegularization-5.0/last_checkpoint.pth.tar\n",
      "Created dataset\n",
      "train: 360, trainmemory: 360, val: 119, test: 120\n",
      "04/25/2024 19:43:15 - INFO - src.SAMIL.libml.models.view_classifier -   Model: WideResNet 28x2\n",
      "04/25/2024 19:43:15 - INFO - __main__ -   Total params for View Model: 5.93M\n",
      "04/25/2024 19:43:15 - INFO - __main__ -   Total params: 2.31M\n",
      "self.param_keys: ['feature_extractor_part1.0.weight', 'feature_extractor_part1.0.bias', 'feature_extractor_part1.3.weight', 'feature_extractor_part1.3.bias', 'feature_extractor_part1.6.weight', 'feature_extractor_part1.6.bias', 'feature_extractor_part1.9.weight', 'feature_extractor_part1.9.bias', 'feature_extractor_part2.0.weight', 'feature_extractor_part2.0.bias', 'feature_extractor_part3.0.weight', 'feature_extractor_part3.0.bias', 'feature_extractor_part3.2.weight', 'feature_extractor_part3.2.bias', 'attention_V.0.weight', 'attention_V.0.bias', 'attention_V.2.weight', 'attention_V.2.bias', 'attention_U.0.weight', 'attention_U.0.bias', 'attention_U.2.weight', 'attention_U.2.bias', 'classifier.0.weight', 'classifier.0.bias']\n",
      "self.buffer_keys: []\n",
      "Resuming from checkpoint: /Users/cho-seonggeun/Documents/GitHub/SAMIL/experiments/SAMIL/Pretrained-NoPretrain/data_seed0/training_seed0/DEV479/ViewRegularization_warmup-Linear_Optimizer-SGD_LrSchedule-CosineLR_LrCycleEpochs-2000_lr-5e-05_wd-0.0001_T-0.03_lambdaViewRegularization-5.0/last_checkpoint.pth.tar\n",
      "04/25/2024 19:43:15 - INFO - __main__ -   ***** Running training *****\n",
      "04/25/2024 19:43:15 - INFO - __main__ -     Task = echo\n",
      "04/25/2024 19:43:15 - INFO - __main__ -     Num Epochs = 2000\n",
      "04/25/2024 19:43:15 - INFO - __main__ -     Total optimization steps = 720000\n",
      "  0%|                                                  | 0/1999 [00:00<?, ?it/s]\n",
      "  0%|                                                   | 0/360 [00:00<?, ?it/s]\u001b[Atorch.Size([59])\n",
      "/Users/cho-seonggeun/Documents/GitHub/SAMIL/src/SAMIL/libml/utils/misc.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predicted_relative_relevance = F.softmax(predicted_relevance/args.T)\n",
      "torch.Size([59])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([61])\n",
      "torch.Size([61])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([96])\n",
      "torch.Size([96])\n",
      "torch.Size([1, 96]) torch.Size([1, 96])\n",
      "torch.Size([71])\n",
      "torch.Size([71])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([69])\n",
      "torch.Size([69])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([67])\n",
      "torch.Size([67])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([165])\n",
      "torch.Size([165])\n",
      "torch.Size([1, 165]) torch.Size([1, 165])\n",
      "torch.Size([69])\n",
      "torch.Size([69])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([50])\n",
      "torch.Size([50])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([152])\n",
      "torch.Size([152])\n",
      "torch.Size([1, 152]) torch.Size([1, 152])\n",
      "torch.Size([57])\n",
      "torch.Size([57])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash launch_experiment.sh run_here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
